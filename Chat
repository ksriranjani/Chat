 from google import generativeai as genai
from google.generativeai import types

# Configure your Gemini API key
genai.configure(api_key="YOUR_API_KEY")

# Create model object for Gemini 1.5
model = genai.GenerativeModel('gemini-1.5-flash')  # or 'gemini-1.5-pro'

def get_llm_response(question):
    try:
        response = model.generate_content(
            contents=[{"role": "user", "parts": [question]}],
            generation_config=types.GenerationConfig(temperature=0.7)
        )
        return response.text.strip() if response and hasattr(response, 'text') else "No response generated."
    
    except Exception as e:
        print("Fallback: Gemini error ->", str(e))
        return "Sorry, I couldn't fetch a response right now."

# Example usage
if __name__ == "__main__":
    query = "Explain how AI works in simple terms."
    print(get_llm_response(query))
