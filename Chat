 import google.generativeai as genai  # version 0.8.5 only

# Configure Gemini API
genai.configure(api_key="YOUR_API_KEY")  # replace with your actual key

# Load available model (limited in 0.8.5)
model = genai.GenerativeModel('models/text-bison-001')

def get_llm_response(question):
    try:
        prompt = f"Answer this user query briefly and clearly: {question}"
        response = model.generate_text(prompt)
        return response.result.strip() if hasattr(response, 'result') else "Sorry, no answer generated."
    except Exception as e:
        print("Gemini Error:", str(e))
        return "Sorry, Icouldn't get an answer right now."



from django.urls import path  # type: ignore
from .views import get_answer  # Your view that handles chatbot interaction

urlpatterns = [
    path('ask/', get_answer, name='ask-question'),  # Endpoint: /api/ask/
]



from django.contrib import admin  # type: ignore
from django.urls import path, include  # type: ignore
from django.http import HttpResponseRedirect  # type: ignore

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/', include('chatbot.urls')),  # API routes for chatbot
    path('', lambda request: HttpResponseRedirect('/api/ask/')),  # Redirect root to chatbot
]
